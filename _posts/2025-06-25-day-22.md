---
layout: post
title: "Day 22 – Trial, Error, and a Step Forward in DDQN Accuracy"
date: 2025-06-25
author: Obaloluwa Wojuade
permalink: /day22.html
tags: ["#DoubleDQn", "#ModelTuning", "#RLChallenges", "DQN"]

what_i_learned: |
  Today was a continuation of my work optimizing the Double DQN model, building on the glucose range insights from yesterday. After a lot of trial and error — adjusting reward functions, tweaking parameters, and re-running tests — I finally saw an improvement in accuracy. The model is now doing a slightly better job keeping glucose levels within the target range, which is a strong sign that things are heading in the right direction.

blockers: |
  No blockers.

reflection: |
  Seeing even a small increase in accuracy felt really rewarding after how much tweaking and testing it took. It reminded me that reinforcement learning is all about patience and iteration. Every small fix adds up, and I’m starting to better understand how the model behaves in different glucose control situations. Still a lot of work ahead, but this was definitely a step forward.
---



