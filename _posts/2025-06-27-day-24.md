---
layout: post
title: "Day 24 – Polishing the Basics: Improving Accuracy with a Fresh DQN Setup"
date: 2025-06-27
author: Obaloluwa Wojuade
permalink: /day24.html
tags: ["#DoubleDQn", "#ModelTuning", "#RLChallenges", "DQN"]

what_i_learned: |
  Today, I returned to my original DQN setup using Gym, focusing on optimizing the model for better glucose control. I restructured some of the logic, adjusted parameters, and worked on fine-tuning the reward function. The goal was to improve overall accuracy how often the model keeps glucose levels in a healthy range — and I’ve started seeing stronger results from those tweaks

blockers: |
  No blockers.

reflection: |
  It felt good to go back to the basics and build on what I’ve learned. Reworking the original DQN helped reinforce my understanding of how small changes in design can lead to better performance. Progress isn’t always fast, but it’s definitely becoming more consistent — and I’m getting closer to building a reliable, health-focused reinforcement learning model.
---




